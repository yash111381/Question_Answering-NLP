{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "conda_amazonei_mxnet_p27",
      "language": "python",
      "name": "conda_amazonei_mxnet_p27"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.15"
    },
    "colab": {
      "name": "LSTM_squad2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9IWJcm27zCU",
        "colab_type": "text"
      },
      "source": [
        "# LSTM MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUalGis17zC5",
        "colab_type": "code",
        "outputId": "8d922f34-a4a5-4a00-b606-e2d2bb242240",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import re\n",
        "import io\n",
        "import nltk\n",
        "import h5py\n",
        "from keras import backend as K\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Input, Dense, Dropout, RepeatVector, Activation, merge, Lambda, Flatten, Reshape\n",
        "from keras.layers import LSTM, Bidirectional, TimeDistributed, GRU\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.layers import concatenate"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsnSpzl_Bgoh",
        "colab_type": "code",
        "outputId": "d0f72715-98a6-4d5e-f2a2-24cae71ceacb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFYd_9iY9Bae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "BASE_PATH = '/gdrive/My Drive/colab_files/project/'\n",
        "if not os.path.exists(BASE_PATH):\n",
        "    os.makedirs(BASE_PATH)\n",
        "DATA_PATH = '/content/'\n",
        "\n",
        "if not os.path.exists(os.path.join(DATA_PATH, 'glove.6B.100d.txt')):\n",
        "    os.chdir(BASE_PATH)\n",
        "    !wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "    !unzip glove.6B.zip\n",
        "    !rm glove.6B.zip\n",
        "    !cp glove.6B.100d.txt /content\n",
        "    # !cp harry_potter.txt /content\n",
        "os.chdir('/content')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmG-bz-4o2DQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKwPTWnXorKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp glove.6B.100d.txt '/content/drive/My Drive/dl_proj_data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpwN8FmS7zDV",
        "colab_type": "code",
        "outputId": "0c6d9e3d-4782-4c7a-ad33-c3c5a8c628e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embeddings_index = {}\n",
        "f = open('/content/glove.6B.100d.txt',encoding=\"utf8\")\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIrUpo9tCtBZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G11Jzt3MCtXc",
        "colab_type": "code",
        "outputId": "01d49ba1-80b2-406c-9cd8-e5b1154d37ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ifa3K4yS7zDo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "context = h5py.File('/content/drive/My Drive/dl_proj_data/context.h5','r')\n",
        "questions = h5py.File('/content/drive/My Drive/dl_proj_data/questions.h5','r')\n",
        "answers = h5py.File('/content/drive/My Drive/dl_proj_data/answers.h5','r')\n",
        "ans_begin = h5py.File('/content/drive/My Drive/dl_proj_data/begin.h5','r')\n",
        "ans_end = h5py.File('/content/drive/My Drive/dl_proj_data/end.h5','r')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRM4VXiC7zDx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c_data = context['context'][:]\n",
        "qn_data = questions['questions'][:]\n",
        "ans_data = answers['answers'][:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoVyevCh7zEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "begin_ans = ans_begin['begin'][:]\n",
        "end_ans = ans_end['end'][:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0acQm-47zEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loding vocabulary\n",
        "word_index = np.load('/content/drive/My Drive/dl_proj_data/words.npy', allow_pickle=True).item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m4AWzet7zEP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix = np.zeros((len(word_index) + 1, 100))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8wb5N0U7zEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(word_index) + 1\n",
        "#embedding_vector_length = 50\n",
        "batch = 128\n",
        "max_span_begin = np.amax(begin_ans)\n",
        "max_span_end = np.amax(end_ans)\n",
        "slce = 10000\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeOm_aFs7zEn",
        "colab_type": "code",
        "outputId": "a3492e57-aa70-4d86-8018-c1e29fadd7ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Vocab Size\")\n",
        "vocab_size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab Size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "119616"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQOduFHS7zEy",
        "colab_type": "code",
        "outputId": "16160a2d-4566-4001-fc93-8297b587762c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        }
      },
      "source": [
        "context_input = Input(shape=(700, ), dtype='int32', name='c_data')\n",
        "context_embed = Embedding(input_dim=vocab_size, output_dim=100, weights=[embedding_matrix], \n",
        "              input_length=700, trainable=False)(context_input)\n",
        "#lstm_out = (LSTM(256, return_sequences=True, implementation=2))(x)\n",
        "drop_1 = Dropout(0.5)(context_embed)\n",
        "#drop_1 = Dropout(0.5)(lstm_out)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiK4j_117zE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ques_input = Input(shape=(100, ), dtype='int32', name='qn_data')\n",
        "question_embed = Embedding(input_dim=vocab_size, output_dim=100, weights=[embedding_matrix], \n",
        "              input_length=100, trainable=False)(ques_input)\n",
        "#lstm_out = (LSTM(256, return_sequences=True, implementation=2))(x)\n",
        "drop_2 = Dropout(0.5)(question_embed)\n",
        "#drop_2 = Dropout(0.5)(lstm_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lEQSnQY7zFE",
        "colab_type": "code",
        "outputId": "624a2565-3fce-4864-8249-ddbb17df8404",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        }
      },
      "source": [
        "merge_layer = concatenate([drop_1, drop_2], axis=1)\n",
        "lstm_layer = (LSTM(512, \n",
        "\n",
        "=2))(merge_layer)\n",
        "drop_3 =  Dropout(0.5)(lstm_layer)\n",
        "softmax_1 = Dense(max_span_begin, activation='softmax')(lstm_layer)\n",
        "softmax_2 = Dense(max_span_end, activation='softmax')(lstm_layer)\n",
        "model = Model(inputs=[context_input, ques_input], outputs=[softmax_1, softmax_2])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "c_data (InputLayer)             (None, 700)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "qn_data (InputLayer)            (None, 100)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 700, 100)     11961600    c_data[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 100, 100)     11961600    qn_data[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 700, 100)     0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 100, 100)     0           embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 800, 100)     0           dropout_1[0][0]                  \n",
            "                                                                 dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 512)          1255424     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 3126)         1603638     lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 3136)         1608768     lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 28,391,030\n",
            "Trainable params: 4,467,830\n",
            "Non-trainable params: 23,923,200\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k2W2hny7zFO",
        "colab_type": "code",
        "outputId": "289ffffc-6191-4308-eadc-a31f945c3452",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        }
      },
      "source": [
        "model_history = model.fit([c_data[:slce], qn_data[:slce]],\n",
        "                        [begin_ans[:slce], end_ans[:slce]], verbose=2,\n",
        "                         batch_size=batch, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/10\n",
            " - 76s - loss: 14.0440 - dense_1_loss: 6.9920 - dense_2_loss: 7.0520 - dense_1_acc: 0.0278 - dense_2_acc: 0.0040\n",
            "Epoch 2/10\n",
            " - 75s - loss: 13.2684 - dense_1_loss: 6.5954 - dense_2_loss: 6.6730 - dense_1_acc: 0.0279 - dense_2_acc: 0.0066\n",
            "Epoch 3/10\n",
            " - 75s - loss: 13.2309 - dense_1_loss: 6.5761 - dense_2_loss: 6.6548 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
            "Epoch 4/10\n",
            " - 76s - loss: 13.2146 - dense_1_loss: 6.5669 - dense_2_loss: 6.6477 - dense_1_acc: 0.0279 - dense_2_acc: 0.0065\n",
            "Epoch 5/10\n",
            " - 75s - loss: 13.1966 - dense_1_loss: 6.5573 - dense_2_loss: 6.6393 - dense_1_acc: 0.0279 - dense_2_acc: 0.0063\n",
            "Epoch 6/10\n",
            " - 75s - loss: 13.1846 - dense_1_loss: 6.5524 - dense_2_loss: 6.6322 - dense_1_acc: 0.0279 - dense_2_acc: 0.0069\n",
            "Epoch 7/10\n",
            " - 75s - loss: 13.1806 - dense_1_loss: 6.5503 - dense_2_loss: 6.6303 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
            "Epoch 8/10\n",
            " - 75s - loss: 13.1781 - dense_1_loss: 6.5495 - dense_2_loss: 6.6285 - dense_1_acc: 0.0279 - dense_2_acc: 0.0066\n",
            "Epoch 9/10\n",
            " - 74s - loss: 13.1599 - dense_1_loss: 6.5404 - dense_2_loss: 6.6195 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
            "Epoch 10/10\n",
            " - 75s - loss: 13.1526 - dense_1_loss: 6.5359 - dense_2_loss: 6.6168 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyNdUPkM7zFb",
        "colab_type": "text"
      },
      "source": [
        "# PREDICTIONS USING TEST DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzNGbW7z7zFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t_context = h5py.File('/content/drive/My Drive/dl_proj_data/context_test.h5','r')\n",
        "t_questions = h5py.File('/content/drive/My Drive/dl_proj_data/questions_test.h5','r')\n",
        "t_answers = h5py.File('/content/drive/My Drive/dl_proj_data/answers_test.h5','r')\n",
        "t_ans_begin = h5py.File('/content/drive/My Drive/dl_proj_data/begin_test.h5','r')\n",
        "t_ans_end = h5py.File('/content/drive/My Drive/dl_proj_data/end_test.h5','r')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jktxsUi7zFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t_c_data = t_context['context'][:]\n",
        "t_qn_data = t_questions['questions'][:]\n",
        "t_ans_data = t_answers['answers'][:]\n",
        "t_begin_ans = t_ans_begin['begin'][:]\n",
        "t_end_ans = t_ans_end['end'][:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rO54QSQ87zFt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_train = np.load('/content/drive/My Drive/dl_proj_data/indxes.npy', allow_pickle=True)\n",
        "index_test = np.load('/content/drive/My Drive/dl_proj_data/indxes_test.npy', allow_pickle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un94gXNF7zF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict([t_c_data,t_qn_data], batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LHLQRF97zGC",
        "colab_type": "code",
        "outputId": "e961f5d9-610e-4b04-c8bd-3068801edf22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(predictions[0].shape, predictions[1].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20302, 3126) (20302, 3136)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5x8WARB7zGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ansBegin = np.zeros((predictions[0].shape[0],), dtype=np.int32)\n",
        "ansEnd = np.zeros((predictions[0].shape[0],),dtype=np.int32) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcSH66tZ7zGL",
        "colab_type": "code",
        "outputId": "6f07b640-cc7e-478e-b403-54dcb3d46f70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for i in range(predictions[0].shape[0]):\n",
        "\tansBegin[i] = predictions[0][i, :].argmax()\n",
        "\tansEnd[i] = predictions[1][i, :].argmax()\n",
        "print(ansBegin.min(), ansBegin.max(), ansEnd.min(), ansEnd.max())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0 7 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6f8c814e-28c5-422d-e89a-245827343d2f",
        "id": "ZJFdJoa0L20n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import pandas as pd\n",
        "pd.Series(ansEnd).value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7    20302\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xECFC58WLpHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answers = {}\n",
        "for i in range(len(vQuestion_id)):\n",
        "    if ansBegin[i] >= len(vContext[i]):\n",
        "        answers[vQuestion_id[i]] = \"\"\n",
        "    elif ansEnd[i] >= len(vContext[i]):\n",
        "        answers[vQuestion_id[i]] = vContextOriginal[i][vToken2CharIdx[i][ansBegin[i]]:]\n",
        "    else:\n",
        "        answers[vQuestion_id[i]] = vContextOriginal[i][vToken2CharIdx[i][ansBegin[i]]:vToken2CharIdx[i][ansEnd[i]]+len(vContext[i][ansEnd[i]])]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}